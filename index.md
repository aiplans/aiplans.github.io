---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

permalink: /
title: Home
layout: home
---

Automatic differentiation libraries and frameworks have enabled much progress in gradient-based learning over the last decade. Recent domain-specific languages for automatic programming hold the promise of unleashing similar progress in other logical disciplines e.g., belief nets, proof nets, and related message passing schemes on tree- and graph-structured data. Concurrently, machines have made steady progress in representing and synthesizing programs. Other workshops have explored these themes separately, yet few have highlighted the synergies between automatic and synthetic programming.

Not only does machine learning benefit from languages for programmable inference, these systems can also be seen as a kind of low-level programming languages in their own right, consisting of differentiable and stochastic primitives. Thanks to recent progress in statistical language modeling, these systems are increasingly capable of generating symbolic functions resembling procedures a human programmer might plausibly write in a high-level language.

Applying techniques from programmable inference to transform and generate programs, and adapting insights gained developing those same programs to drive innovation in higher-order AD and probabilistic programming is a now virtuous cycle. We envision cooperation between automatic and synthetic programming will continue to grow as researchers become more accustomed to outsourcing low-level reasoning tasks to these systems.

Our workshop is designed to be as inclusive as possible towards researchers of various backgrounds working on automated learning and reasoning in programming languages and neurosymbolic systems. For illustration, we include the following non-exhaustive list of topics:

* Differentiable programming / algorithmic differentiation
* Probabilistic programming / statistical inference
* Declarative programming / constraint programming
* Dynamic programming / reinforcement learning
* Functional programming / Î»-calculus
* Array programming / linear algebra
* Semiring programming / message passing
* Logic programming / Relational programming
* Meta-programming / meta-learning
* Computer aided reasoning / automatic theorem proving
* Domain-specific languages and compilers
* Inductive programming / programming by example

We would like to particularly encourage developers of languages, frameworks and libraries to submit their ongoing work for evaluation. Those who traditionally publish in venues such as SIGPLAN and SIGSOFT are encouraged to consider submitting theoretical work that may be relevant to machine learning community. Details regarding evaluation criteria, deadlines and workshop logistics can be found under the [AIPLANS CFP](callforpapers.md).